{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bcc6ca00",
   "metadata": {},
   "source": [
    "#  Generative AI Model\n",
    "\n",
    "## Different approaches of how such game can be re-created.\n",
    "\n",
    "### Machine Learning Classification:\n",
    "\n",
    "#### First approach :\n",
    "\n",
    "The first approach would be Machine Learning Classification. Indeed, in the context of our issue, this approach would be rather simple and fast, thanks to the characteristics of each of our gaits that seem relatively independent of each other. Here, the objective is to classify each gait to recreate our match.\n",
    "One could therefore consider the Random Forest algorithm. On the one hand, this algorithm would allow us to avoid overfitting, and on the other hand, it performs well when it comes to classifying data that has an imbalance in the distribution of classes, as in our case where the \"run\" label has 552 samples while the \"shot\" label has 18. However, in the context of our problem, it's an approach that doesn't handle dependencies between gaits, which can be inconvenient in our case.\n",
    "\n",
    "### Sequence Modeling with Recurrent Neural Networks (RNNs):\n",
    "\n",
    "#### Second approach :\n",
    "\n",
    "The second envisaged approach would be a deep learning approach, namely Sequence Modeling with Recurrent Neural Networks (RNNs). Indeed, RNNs are rather suitable for detecting sequential dependencies, which can be very useful for understanding the successive actions of players. We can thus use the LSTM (Long Short-Term Memory) algorithm, which proves to be very effective in detecting dependencies, but not only. Indeed, the RNN approach may face an issue of vanishing gradients, a problem that can be alleviated by this LSTM algorithm. However, like any deep learning approach, difficulties can be encountered in terms of interpretability and explainability of the obtained results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "835f5f2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import json\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import LSTM, Dense, Reshape,Input,Embedding,Masking\n",
    "from tensorflow.keras.models import Sequential,Model\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "with open(\"../Data/match_1.json\", 'r') as json_file:\n",
    "    data = json.load(json_file)\n",
    "\n",
    "with open(\"../Data/match_2.json\", 'r') as json_file:\n",
    "    data2 = json.load(json_file)\n",
    "\n",
    "df = data + data2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45f8c0de",
   "metadata": {},
   "source": [
    "## LSTM approach\n",
    "\n",
    "To solve this problem, I decided to use the RNN's LSTM algortihm, as the RNN will allow us to work with our gait sequences and the LSTM will allow us to solve the gradient vanishing problem that is linked to the memory of RNN models.\n",
    "To do this, I'll explain the mathematical theory behind the algorithm.\n",
    "The LSTM cell is the basic unit of the algortithm, which contains two main states: short-term and long-term memory. To control the flow of information within the cell, it uses so-called gates.\n",
    "\n",
    "There are 3 of them:\n",
    "\n",
    "An forget gate, which filters the information contained in the previous memory cell using a ft function.\n",
    "<img src=\"../Images/Function_ft.png\" alt=\"function ft\" width=\"200\"/>\n",
    "\n",
    "With xt corresponding to the input data to the neural network, ht-1 corresponds to the output value predicted by the previous LSTM layer. From a mathematical point of view, [ht-1,xt] is the concatenation of the arrays xt and ht-1. Wf corresponds to the weight of the neurons and bf to the bias with sigmoid as activation function. This function will enable us to filter the relevant values to be retained from our previous memory cell. Our sigmoide function will return values between 0 and 1.\n",
    "\n",
    "<img src=\"../Images/ct.png\" alt=\"maj ct\" width=\"100\"/>\n",
    "\n",
    "This will allow us to multiply our ft function and Ct-1, which corresponds to the value of the previous memory cell. Here too, we'll have values between 0 and 1. If the result of the multiplication is close to 1, the value will be kept, whereas if it's close to 0, it will be ignored. In short, the purpose of the forgetting gate is to sort out the old values contained in the previous memory cell and thus update our memory cell at time t.\n",
    "\n",
    "Next, we have the input gate, whose purpose is to decide which of the new incoming values xt will be authorized to enter the memory cell. Those that are most relevant will be placed in the memory cell and will help in the decision at time t.\n",
    "<img src=\"../Images/Input_gate.png\" alt=\"input gate\" width=\"250\"/>\n",
    "Here, we'll start with the it function, whose activation function is the sigmoid, which will output values between 0 and 1. Then we'll do the same thing, but our ~Ct function will have the tangent as its activation function, which will output values between -1 and 1. Term-by-term multiplication between our two functions will determine which values will be authorized to enter the memory cell. As with the forget gate, we'll keep the values closest to 1, while those closest to 0 will be ignored.\n",
    "In short, the input gate will select the most relevant input values and then enter them into the memory cell, so that these values will have an impact on decisions at time t and perhaps t-1, depending on our port of forgetfulness.\n",
    "\n",
    "Once the work on these two gates has been completed, our memory will be updated as follows: \n",
    "<img src=\"../Images/memory.png\" alt=\"maj ctfinal\" width=\"200\"/>\n",
    "Finally, we have an output gate that will allow us to determine which part of our long-term memory will be exposed as an output.\n",
    "\n",
    "<img src=\"../Images/Output_gate.png\" alt=\"Output gate\" width=\"200\"/>\n",
    "The decision is made using the ht output, which depends on the information in the ct memory cell and the xt input values.\n",
    "\n",
    "Just below is a flow chart showing how an LSTM memory cell works:\n",
    "<img src=\"../Images/flow-chart.png\" alt=\"Flow chart\" width=\"500\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3995fd32",
   "metadata": {},
   "source": [
    "To use our LSTM algorithm, a challenge arises: it only considers fixed-length temporal sequences that do not vary. We will need to perform preprocessing to address this issue."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "add6a79e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1187, 723)\n",
      "Epoch 1/50\n",
      "38/38 [==============================] - 21s 416ms/step - loss: 214.7617 - mae: 2.7077 - accuracy: 0.0169\n",
      "Epoch 2/50\n",
      "38/38 [==============================] - 16s 428ms/step - loss: 197.5533 - mae: 2.5766 - accuracy: 0.0177\n",
      "Epoch 3/50\n",
      "38/38 [==============================] - 17s 438ms/step - loss: 183.7370 - mae: 2.4236 - accuracy: 0.0177\n",
      "Epoch 4/50\n",
      "38/38 [==============================] - 17s 441ms/step - loss: 174.1727 - mae: 2.2865 - accuracy: 0.0177\n",
      "Epoch 5/50\n",
      "38/38 [==============================] - 18s 472ms/step - loss: 167.0333 - mae: 2.1938 - accuracy: 0.0177\n",
      "Epoch 6/50\n",
      "38/38 [==============================] - 21s 555ms/step - loss: 161.5161 - mae: 2.1220 - accuracy: 0.0177\n",
      "Epoch 7/50\n",
      "38/38 [==============================] - 20s 516ms/step - loss: 157.7229 - mae: 2.1060 - accuracy: 0.0177\n",
      "Epoch 8/50\n",
      "38/38 [==============================] - 19s 505ms/step - loss: 154.9274 - mae: 2.0848 - accuracy: 0.0177\n",
      "Epoch 9/50\n",
      "38/38 [==============================] - 19s 513ms/step - loss: 152.8321 - mae: 2.0874 - accuracy: 0.0177\n",
      "Epoch 10/50\n",
      "38/38 [==============================] - 18s 477ms/step - loss: 151.3711 - mae: 2.0860 - accuracy: 0.0177\n",
      "Epoch 11/50\n",
      "38/38 [==============================] - 19s 511ms/step - loss: 150.3626 - mae: 2.0943 - accuracy: 0.0177\n",
      "Epoch 12/50\n",
      "38/38 [==============================] - 20s 527ms/step - loss: 149.6758 - mae: 2.0989 - accuracy: 0.0177\n",
      "Epoch 13/50\n",
      "38/38 [==============================] - 20s 514ms/step - loss: 149.1807 - mae: 2.1140 - accuracy: 0.0194\n",
      "Epoch 14/50\n",
      "38/38 [==============================] - 20s 529ms/step - loss: 148.8717 - mae: 2.1194 - accuracy: 0.0152\n",
      "Epoch 15/50\n",
      "38/38 [==============================] - 19s 511ms/step - loss: 148.6656 - mae: 2.1245 - accuracy: 0.0152\n",
      "Epoch 16/50\n",
      "38/38 [==============================] - 20s 534ms/step - loss: 148.5398 - mae: 2.1267 - accuracy: 0.0152\n",
      "Epoch 17/50\n",
      "38/38 [==============================] - 19s 502ms/step - loss: 148.4564 - mae: 2.1330 - accuracy: 0.0135\n",
      "Epoch 18/50\n",
      "38/38 [==============================] - 18s 477ms/step - loss: 148.4043 - mae: 2.1599 - accuracy: 0.0194\n",
      "Epoch 19/50\n",
      "38/38 [==============================] - 19s 499ms/step - loss: 148.3883 - mae: 2.1719 - accuracy: 0.0194\n",
      "Epoch 20/50\n",
      "38/38 [==============================] - 21s 563ms/step - loss: 148.3461 - mae: 2.1462 - accuracy: 0.0194\n",
      "Epoch 21/50\n",
      "38/38 [==============================] - 17s 460ms/step - loss: 148.3277 - mae: 2.1491 - accuracy: 0.0194\n",
      "Epoch 22/50\n",
      "38/38 [==============================] - 18s 468ms/step - loss: 148.3235 - mae: 2.1491 - accuracy: 0.0194\n",
      "Epoch 23/50\n",
      "38/38 [==============================] - 18s 482ms/step - loss: 148.3179 - mae: 2.1556 - accuracy: 0.0194\n",
      "Epoch 24/50\n",
      "38/38 [==============================] - 18s 482ms/step - loss: 148.3109 - mae: 2.1534 - accuracy: 0.0194\n",
      "Epoch 25/50\n",
      "38/38 [==============================] - 18s 480ms/step - loss: 148.3069 - mae: 2.1476 - accuracy: 0.0169\n",
      "Epoch 26/50\n",
      "38/38 [==============================] - 17s 447ms/step - loss: 148.3066 - mae: 2.1538 - accuracy: 0.0152\n",
      "Epoch 27/50\n",
      "38/38 [==============================] - 19s 512ms/step - loss: 148.3129 - mae: 2.1487 - accuracy: 0.0152\n",
      "Epoch 28/50\n",
      "38/38 [==============================] - 20s 526ms/step - loss: 148.3097 - mae: 2.1531 - accuracy: 0.0143\n",
      "Epoch 29/50\n",
      "38/38 [==============================] - 19s 490ms/step - loss: 148.3019 - mae: 2.1553 - accuracy: 0.0143\n",
      "Epoch 30/50\n",
      "38/38 [==============================] - 18s 472ms/step - loss: 148.3085 - mae: 2.1467 - accuracy: 0.0169\n",
      "Epoch 31/50\n",
      "38/38 [==============================] - 18s 461ms/step - loss: 148.3109 - mae: 2.1547 - accuracy: 0.0152\n",
      "Epoch 32/50\n",
      "38/38 [==============================] - 19s 510ms/step - loss: 148.3176 - mae: 2.1566 - accuracy: 0.0101\n",
      "Epoch 33/50\n",
      "38/38 [==============================] - 18s 480ms/step - loss: 148.3090 - mae: 2.1550 - accuracy: 0.0152\n",
      "Epoch 34/50\n",
      "38/38 [==============================] - 18s 475ms/step - loss: 148.3035 - mae: 2.1590 - accuracy: 0.0194\n",
      "Epoch 35/50\n",
      "38/38 [==============================] - 18s 473ms/step - loss: 148.3045 - mae: 2.1476 - accuracy: 0.0194\n",
      "Epoch 36/50\n",
      "38/38 [==============================] - 18s 468ms/step - loss: 148.2837 - mae: 2.1555 - accuracy: 0.0194\n",
      "Epoch 37/50\n",
      "38/38 [==============================] - 19s 499ms/step - loss: 148.1867 - mae: 2.1452 - accuracy: 0.0160\n",
      "Epoch 38/50\n",
      "38/38 [==============================] - 18s 487ms/step - loss: 148.1256 - mae: 2.1416 - accuracy: 0.0194\n",
      "Epoch 39/50\n",
      "38/38 [==============================] - 21s 545ms/step - loss: 148.0659 - mae: 2.1446 - accuracy: 0.0194\n",
      "Epoch 40/50\n",
      "38/38 [==============================] - 19s 492ms/step - loss: 147.8512 - mae: 2.1442 - accuracy: 0.0194\n",
      "Epoch 41/50\n",
      "38/38 [==============================] - 19s 487ms/step - loss: 147.6134 - mae: 2.1396 - accuracy: 0.0152\n",
      "Epoch 42/50\n",
      "38/38 [==============================] - 19s 488ms/step - loss: 147.4819 - mae: 2.1371 - accuracy: 0.0202\n",
      "Epoch 43/50\n",
      "38/38 [==============================] - 18s 469ms/step - loss: 147.3763 - mae: 2.1452 - accuracy: 0.0194\n",
      "Epoch 44/50\n",
      "38/38 [==============================] - 18s 475ms/step - loss: 147.3229 - mae: 2.1401 - accuracy: 0.0118\n",
      "Epoch 45/50\n",
      "38/38 [==============================] - 18s 472ms/step - loss: 147.2539 - mae: 2.1425 - accuracy: 0.0126\n",
      "Epoch 46/50\n",
      "38/38 [==============================] - 18s 466ms/step - loss: 146.6461 - mae: 2.1291 - accuracy: 0.0143\n",
      "Epoch 47/50\n",
      "38/38 [==============================] - 18s 473ms/step - loss: 144.9920 - mae: 2.1223 - accuracy: 0.0160\n",
      "Epoch 48/50\n",
      "38/38 [==============================] - 18s 479ms/step - loss: 144.4649 - mae: 2.1085 - accuracy: 0.0169\n",
      "Epoch 49/50\n",
      "38/38 [==============================] - 18s 473ms/step - loss: 144.2107 - mae: 2.1082 - accuracy: 0.0169\n",
      "Epoch 50/50\n",
      "38/38 [==============================] - 18s 472ms/step - loss: 144.0827 - mae: 2.1014 - accuracy: 0.0152\n"
     ]
    }
   ],
   "source": [
    "# Definition of the model creation function\n",
    "def create_lstm_model(max_norm_length, lstm_units=120, dense_units=723):\n",
    "    # Branch for norm data\n",
    "    input_norm = Input(shape=(max_norm_length, 1), name='input_norm')\n",
    "    masked_norm = Masking(mask_value=0.0)(input_norm)\n",
    "    lstm_norm = LSTM(lstm_units, name='lstm_norm')(masked_norm)\n",
    "\n",
    "    # Dense layer for norm prediction\n",
    "    output_norm = Dense(dense_units, activation='relu', name='output_norm')(lstm_norm)\n",
    "\n",
    "    # Model definition\n",
    "    model = Model(inputs=input_norm, outputs=output_norm)\n",
    "\n",
    "    return model\n",
    "\n",
    "# Data preprocessing\n",
    "norms = [entry[\"norm\"] for entry in df]\n",
    "labels = [entry[\"label\"] for entry in df]\n",
    "\n",
    "# Padding norm sequences\n",
    "max_norm_length = max(len(norm) for norm in norms)\n",
    "padded_norms = pad_sequences(norms, padding='post', maxlen=max_norm_length, dtype='float32')\n",
    "# Norms are good: well-padded with the max_norm_length\n",
    "\n",
    "# Remove the first element from each sequence in padded_norms\n",
    "padded_norms_input = padded_norms[1:, :]\n",
    "padded_norms_output = padded_norms[:-1, :]\n",
    "\n",
    "# Convert data to numpy arrays\n",
    "labels_array = np.array(labels)\n",
    "\n",
    "# Transform labels into numbers\n",
    "label_encoder = LabelEncoder()\n",
    "encoded_labels = label_encoder.fit_transform(labels_array)\n",
    "\n",
    "# One-hot encoding of labels\n",
    "one_hot_labels = to_categorical(encoded_labels)\n",
    "\n",
    "one_hot_labels_input = one_hot_labels[1:, :]\n",
    "one_hot_labels_output = one_hot_labels[:-1, :]\n",
    "\n",
    "# Definition of input shapes\n",
    "input_shape_label = (len(one_hot_labels[0]), 1)  # Shape of label data\n",
    "\n",
    "# Model creation\n",
    "model = create_lstm_model(max_norm_length)\n",
    "\n",
    "# Model compilation\n",
    "# optimizer = Adam(lr=0.001)  # Adjust the learning rate according to your needs\n",
    "model.compile(optimizer='adam', loss='mean_squared_error', metrics=['mae','accuracy'])\n",
    "\n",
    "print(padded_norms.shape)\n",
    "# Model training\n",
    "predictions = model.fit(padded_norms_input, padded_norms_output, epochs=50, batch_size=32)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "388970dd",
   "metadata": {},
   "source": [
    "Here, the goal is to generate sequences based on the input sequences. Therefore, I performed padding to ensure that all sequences are of equal length, allowing the LSTM model to process them. To recreate the match, the first step involved generating sequences that make sense in the succession of movements. I shifted the inputs and outputs so that the output corresponds to the norm following the input. Then, in a second step, I aimed to predict the labels associated with these generated sequences."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "63ebb2e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "38/38 [==============================] - 10s 161ms/step\n",
      "[[34.029617  0.       38.363422 ...  0.        0.        0.      ]\n",
      " [33.936417  0.       38.25449  ...  0.        0.        0.      ]\n",
      " [33.96271   0.       38.284317 ...  0.        0.        0.      ]\n",
      " ...\n",
      " [34.594425  0.       39.013397 ...  0.        0.        0.      ]\n",
      " [35.650845  0.       40.195686 ...  0.        0.        0.      ]\n",
      " [33.971966  0.       38.295265 ...  0.        0.        0.      ]]\n"
     ]
    }
   ],
   "source": [
    "predictions = model.predict(padded_norms)\n",
    "print(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "4bfe8751",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1187, 723)\n",
      "Model: \"model_16\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_sequence (InputLayer  [(None, 723, 1)]          0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " masking_22 (Masking)        (None, 723, 1)            0         \n",
      "                                                                 \n",
      " lstm_16 (LSTM)              (None, 100)               40800     \n",
      "                                                                 \n",
      " dense_12 (Dense)            (None, 9)                 909       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 41709 (162.93 KB)\n",
      "Trainable params: 41709 (162.93 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n",
      "Epoch 1/10\n",
      "30/30 [==============================] - 20s 491ms/step - loss: 1.4152 - accuracy: 0.5501 - val_loss: 0.9705 - val_accuracy: 0.7605\n",
      "Epoch 2/10\n",
      "30/30 [==============================] - 12s 417ms/step - loss: 1.0719 - accuracy: 0.6902 - val_loss: 0.7745 - val_accuracy: 0.8151\n",
      "Epoch 3/10\n",
      "30/30 [==============================] - 13s 429ms/step - loss: 0.9463 - accuracy: 0.7313 - val_loss: 0.7285 - val_accuracy: 0.8109\n",
      "Epoch 4/10\n",
      "30/30 [==============================] - 13s 427ms/step - loss: 0.9150 - accuracy: 0.7334 - val_loss: 0.6722 - val_accuracy: 0.8193\n",
      "Epoch 5/10\n",
      "30/30 [==============================] - 13s 447ms/step - loss: 0.8800 - accuracy: 0.7387 - val_loss: 0.6670 - val_accuracy: 0.8235\n",
      "Epoch 6/10\n",
      "30/30 [==============================] - 14s 455ms/step - loss: 0.8768 - accuracy: 0.7429 - val_loss: 0.6415 - val_accuracy: 0.8193\n",
      "Epoch 7/10\n",
      "30/30 [==============================] - 13s 450ms/step - loss: 0.8695 - accuracy: 0.7387 - val_loss: 0.6412 - val_accuracy: 0.8193\n",
      "Epoch 8/10\n",
      "30/30 [==============================] - 13s 450ms/step - loss: 0.8595 - accuracy: 0.7376 - val_loss: 0.6297 - val_accuracy: 0.8319\n",
      "Epoch 9/10\n",
      "30/30 [==============================] - 13s 443ms/step - loss: 0.8439 - accuracy: 0.7503 - val_loss: 0.6238 - val_accuracy: 0.8193\n",
      "Epoch 10/10\n",
      "30/30 [==============================] - 13s 443ms/step - loss: 0.8250 - accuracy: 0.7513 - val_loss: 0.6284 - val_accuracy: 0.8151\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x1b409f06700>"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Extract sequences and labels\n",
    "sequences = [example[\"norm\"] for example in df]\n",
    "labels = [example[\"label\"] for example in df]\n",
    "\n",
    "# Convert labels to numerical categories\n",
    "label_mapping = {label: idx for idx, label in enumerate(np.unique(labels))}\n",
    "labels_numeric = np.array([label_mapping[label] for label in labels])\n",
    "labels_one_hot = to_categorical(labels_numeric)\n",
    "\n",
    "# Padding sequences to have the same length\n",
    "padded_sequences = pad_sequences(sequences, dtype='float32', padding='post', truncating='post')\n",
    "print(padded_sequences.shape)\n",
    "\n",
    "# Define accelerometer time sequence as input\n",
    "input_sequence = Input(shape=(padded_sequences.shape[1], 1), name='input_sequence')\n",
    "\n",
    "# Add a masking layer to account for padding\n",
    "masked_input = Masking(mask_value=0.0)(input_sequence)\n",
    "\n",
    "# LSTM layer to capture temporal sequences\n",
    "lstm_output = LSTM(100)(masked_input)\n",
    "\n",
    "# Dense layer for final prediction\n",
    "output = Dense(len(label_mapping), activation='softmax')(lstm_output)\n",
    "\n",
    "# Create the model\n",
    "model = Model(inputs=input_sequence, outputs=output)\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Display the model structure\n",
    "model.summary()\n",
    "\n",
    "# Train the model\n",
    "model.fit(padded_sequences, labels_one_hot, epochs=10, batch_size=32, validation_split=0.2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd764215",
   "metadata": {},
   "source": [
    "Here, I created a model to predict the new labels for the generated sequences, facilitating the recreation of our match."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "c491c383",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "38/38 [==============================] - 7s 133ms/step\n"
     ]
    }
   ],
   "source": [
    "labels_predicted = model.predict(predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c97fbcf6",
   "metadata": {},
   "source": [
    "Unfortunately, the output does not have the desired meaning; the movements for recreating the match are only runs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "50326a8a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['run', 'run', 'run', 'run', 'run', 'run', 'run', 'run', 'run', 'run', 'run', 'run', 'run', 'run', 'run', 'run', 'run', 'run', 'run', 'run', 'run', 'run', 'run', 'run', 'run', 'run', 'run', 'run', 'run', 'run', 'run', 'run', 'run', 'run', 'run', 'run', 'run', 'run', 'run', 'run', 'run', 'run', 'run', 'run', 'run', 'run', 'run', 'run', 'run', 'run', 'run', 'run', 'run', 'run', 'run', 'run', 'run', 'run', 'run', 'run', 'run', 'run', 'run', 'run', 'run', 'run', 'run', 'run', 'run', 'run', 'run', 'run', 'run', 'run', 'run', 'run', 'run', 'run', 'run', 'run', 'run', 'run', 'run', 'run', 'run', 'run', 'run', 'run', 'run', 'run', 'run', 'run', 'run', 'run', 'run', 'run', 'run', 'run', 'run', 'run', 'run', 'run', 'run', 'run', 'run', 'run', 'run', 'run', 'run', 'run', 'run', 'run', 'run', 'run', 'run', 'run', 'run', 'run', 'run', 'run', 'run', 'run', 'run', 'run', 'run', 'run', 'run', 'run', 'run', 'run', 'run', 'run', 'run', 'run', 'run', 'run', 'run', 'run', 'run', 'run', 'run', 'run', 'run', 'run', 'run', 'run', 'run', 'run', 'run', 'run', 'run', 'run', 'run', 'run', 'run', 'run', 'run', 'run', 'run', 'run', 'run', 'run', 'run', 'run', 'run', 'run', 'run', 'run', 'run', 'run', 'run', 'run', 'run', 'run', 'run', 'run', 'run', 'run', 'run', 'run', 'run', 'run', 'run', 'run', 'run', 'run', 'run', 'run', 'run', 'run', 'run', 'run', 'run', 'run', 'run', 'run', 'run', 'run', 'run', 'run', 'run', 'run', 'run', 'run', 'run', 'run', 'run', 'run', 'run', 'run', 'run', 'run', 'run', 'run', 'run', 'run', 'run', 'run', 'run', 'run', 'run', 'run', 'run', 'run', 'run', 'run', 'run', 'run', 'run', 'run', 'run', 'run', 'run', 'run', 'run', 'run', 'run', 'run', 'run', 'run', 'run', 'run', 'run', 'run', 'run', 'run', 'run', 'run', 'run', 'run', 'run', 'run', 'run', 'run', 'run', 'run', 'run', 'run', 'run', 'run', 'run', 'run', 'run', 'run', 'run', 'run', 'run', 'run', 'run', 'run', 'run', 'run', 'run', 'run', 'run', 'run', 'run', 'run', 'run', 'run', 'run', 'run', 'run', 'run', 'run', 'run', 'run', 'run', 'run', 'run', 'run', 'run', 'run', 'run', 'run', 'run', 'run', 'run', 'run', 'run', 'run', 'run', 'run', 'run', 'run', 'run', 'run', 'run', 'run', 'run', 'run', 'run', 'run', 'run', 'run', 'run', 'run', 'run', 'run', 'run', 'run', 'run', 'run', 'run', 'run', 'run', 'run', 'run', 'run', 'run', 'run', 'run', 'run', 'run', 'run', 'run', 'run', 'run', 'run', 'run', 'run', 'run', 'run', 'run', 'run', 'run', 'run', 'run', 'run', 'run', 'run', 'run', 'run', 'run', 'run', 'run', 'run', 'run', 'run', 'run', 'run', 'run', 'run', 'run', 'run', 'run', 'run', 'run', 'run', 'run', 'run', 'run', 'run', 'run', 'run', 'run', 'run', 'run', 'run', 'run', 'run', 'run', 'run', 'run', 'run', 'run', 'run', 'run', 'run', 'run', 'run', 'run', 'run', 'run', 'run', 'run', 'run', 'run', 'run', 'run', 'run', 'run', 'run', 'run', 'run', 'run', 'run', 'run', 'run', 'run', 'run', 'run', 'run', 'run', 'run', 'run', 'run', 'run', 'run', 'run', 'run', 'run', 'run', 'run', 'run', 'run', 'run', 'run', 'run', 'run', 'run', 'run', 'run', 'run', 'run', 'run', 'run', 'run', 'run', 'run', 'run', 'run', 'run', 'run', 'run', 'run', 'run', 'run', 'run', 'run', 'run', 'run', 'run', 'run', 'run', 'run', 'run', 'run', 'run', 'run', 'run', 'run', 'run', 'run', 'run', 'run', 'run', 'run', 'run', 'run', 'run', 'run', 'run', 'run', 'run', 'run', 'run', 'run', 'run', 'run', 'run', 'run', 'run', 'run', 'run', 'run', 'run', 'run', 'run', 'run', 'run', 'run', 'run', 'run', 'run', 'run', 'run', 'run', 'run', 'run', 'run', 'run', 'run', 'run', 'run', 'run', 'run', 'run', 'run', 'run', 'run', 'run', 'run', 'run', 'run', 'run', 'run', 'run', 'run', 'run', 'run', 'run', 'run', 'run', 'run', 'run', 'run', 'run', 'run', 'run', 'run', 'run', 'run', 'run', 'run', 'run', 'run', 'run', 'run', 'run', 'run', 'run', 'run', 'run', 'run', 'run', 'run', 'run', 'run', 'run', 'run', 'run', 'run', 'run', 'run', 'run', 'run', 'run', 'run', 'run', 'run', 'run', 'run', 'run', 'run', 'run', 'run', 'run', 'run', 'run', 'run', 'run', 'run', 'run', 'run', 'run', 'run', 'run', 'run', 'run', 'run', 'run', 'run', 'run', 'run', 'run', 'run', 'run', 'run', 'run', 'run', 'run', 'run', 'run', 'run', 'run', 'run', 'run', 'run', 'run', 'run', 'run', 'run', 'run', 'run', 'run', 'run', 'run', 'run', 'run', 'run', 'run', 'run', 'run', 'run', 'run', 'run', 'run', 'run', 'run', 'run', 'run', 'run', 'run', 'run', 'run', 'run', 'run', 'run', 'run', 'run', 'run', 'run', 'run', 'run', 'run', 'run', 'run', 'run', 'run', 'run', 'run', 'run', 'run', 'run', 'run', 'run', 'run', 'run', 'run', 'run', 'run', 'run', 'run', 'run', 'run', 'run', 'run', 'run', 'run', 'run', 'run', 'run', 'run', 'run', 'run', 'run', 'run', 'run', 'run', 'run', 'run', 'run', 'run', 'run', 'run', 'run', 'run', 'run', 'run', 'run', 'run', 'run', 'run', 'run', 'run', 'run', 'run', 'run', 'run', 'run', 'run', 'run', 'run', 'run', 'run', 'run', 'run', 'run', 'run', 'run', 'run', 'run', 'run', 'run', 'run', 'run', 'run', 'run', 'run', 'run', 'run', 'run', 'run', 'run', 'run', 'run', 'run', 'run', 'run', 'run', 'run', 'run', 'run', 'run', 'run', 'run', 'run', 'run', 'run', 'run', 'run', 'run', 'run', 'run', 'run', 'run', 'run', 'run', 'run', 'run', 'run', 'run', 'run', 'run', 'run', 'run', 'run', 'run', 'run', 'run', 'run', 'run', 'run', 'run', 'run', 'run', 'run', 'run', 'run', 'run', 'run', 'run', 'run', 'run', 'run', 'run', 'run', 'run', 'run', 'run', 'run', 'run', 'run', 'run', 'run', 'run', 'run', 'run', 'run', 'run', 'run', 'run', 'run', 'run', 'run', 'run', 'run', 'run', 'run', 'run', 'run', 'run', 'run', 'run', 'run', 'run', 'run', 'run', 'run', 'run', 'run', 'run', 'run', 'run', 'run', 'run', 'run', 'run', 'run', 'run', 'run', 'run', 'run', 'run', 'run', 'run', 'run', 'run', 'run', 'run', 'run', 'run', 'run', 'run', 'run', 'run', 'run', 'run', 'run', 'run', 'run', 'run', 'run', 'run', 'run', 'run', 'run', 'run', 'run', 'run', 'run', 'run', 'run', 'run', 'run', 'run', 'run', 'run', 'run', 'run', 'run', 'run', 'run', 'run', 'run', 'run', 'run', 'run', 'run', 'run', 'run', 'run', 'run', 'run', 'run', 'run', 'run', 'run', 'run', 'run', 'run', 'run', 'run', 'run', 'run', 'run', 'run', 'run', 'run', 'run', 'run', 'run', 'run', 'run', 'run', 'run', 'run', 'run', 'run', 'run', 'run', 'run', 'run', 'run', 'run', 'run', 'run', 'run', 'run', 'run', 'run', 'run', 'run', 'run', 'run', 'run', 'run', 'run', 'run', 'run', 'run', 'run', 'run', 'run', 'run', 'run', 'run', 'run', 'run', 'run', 'run', 'run', 'run', 'run', 'run', 'run', 'run', 'run', 'run', 'run', 'run', 'run', 'run', 'run', 'run', 'run', 'run', 'run', 'run', 'run', 'run', 'run', 'run', 'run', 'run', 'run', 'run', 'run', 'run', 'run', 'run', 'run', 'run', 'run', 'run', 'run', 'run', 'run', 'run', 'run', 'run', 'run', 'run', 'run', 'run', 'run', 'run', 'run', 'run', 'run', 'run', 'run', 'run', 'run', 'run', 'run', 'run', 'run', 'run', 'run', 'run', 'run', 'run', 'run', 'run', 'run', 'run', 'run', 'run', 'run', 'run', 'run', 'run', 'run', 'run', 'run', 'run', 'run', 'run', 'run', 'run', 'run', 'run', 'run', 'run', 'run', 'run', 'run', 'run', 'run', 'run', 'run', 'run', 'run', 'run', 'run', 'run', 'run', 'run', 'run', 'run', 'run', 'run', 'run', 'run', 'run', 'run', 'run', 'run', 'run', 'run', 'run', 'run', 'run', 'run', 'run', 'run', 'run', 'run', 'run', 'run', 'run', 'run', 'run', 'run', 'run', 'run', 'run', 'run', 'run', 'run', 'run', 'run', 'run', 'run', 'run', 'run', 'run', 'run', 'run', 'run', 'run', 'run', 'run', 'run', 'run', 'run', 'run', 'run', 'run', 'run', 'run', 'run', 'run', 'run', 'run', 'run', 'run', 'run', 'run', 'run', 'run', 'run', 'run', 'run', 'run', 'run', 'run', 'run', 'run', 'run', 'run', 'run', 'run', 'run', 'run', 'run', 'run', 'run', 'run', 'run', 'run', 'run', 'run', 'run', 'run', 'run', 'run', 'run', 'run', 'run', 'run', 'run', 'run', 'run', 'run', 'run', 'run', 'run', 'run', 'run', 'run', 'run', 'run', 'run', 'run', 'run', 'run', 'run', 'run', 'run', 'run', 'run', 'run', 'run', 'run', 'run', 'run', 'run', 'run', 'run', 'run', 'run', 'run', 'run', 'run', 'run', 'run', 'run', 'run', 'run', 'run', 'run', 'run', 'run', 'run', 'run', 'run', 'run', 'run', 'run', 'run', 'run', 'run', 'run', 'run', 'run', 'run', 'run', 'run', 'run', 'run', 'run', 'run', 'run', 'run', 'run', 'run', 'run', 'run', 'run', 'run', 'run', 'run', 'run', 'run']\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# Similarly here\n",
    "predicted_labels_numeric = np.argmax(labels_predicted, axis=1)\n",
    "\n",
    "# Convert true labels to numerical labels\n",
    "true_labels_numeric = np.argmax(labels_one_hot, axis=1)\n",
    "\n",
    "# Reverse the mapping to get a mapping from numbers to labels\n",
    "inverse_label_mapping = {idx: label for label, idx in label_mapping.items()}\n",
    "\n",
    "# Convert predicted numerical labels to original labels\n",
    "predicted_labels_original = [inverse_label_mapping[idx] for idx in predicted_labels_numeric]\n",
    "print(predicted_labels_original)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f11c28d6",
   "metadata": {},
   "source": [
    "Below, I attempted to combine the models to generate both at the same time, but unfortunately, the output still has the same issue where my output is only walks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "13713a87",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "30/30 [==============================] - 22s 571ms/step - loss: 1.4947 - accuracy: 0.5153 - val_loss: 0.9444 - val_accuracy: 0.7731\n",
      "Epoch 2/10\n",
      "30/30 [==============================] - 15s 498ms/step - loss: 1.0714 - accuracy: 0.6986 - val_loss: 0.7747 - val_accuracy: 0.8025\n",
      "Epoch 3/10\n",
      "30/30 [==============================] - 15s 503ms/step - loss: 0.9556 - accuracy: 0.7323 - val_loss: 0.7130 - val_accuracy: 0.8193\n",
      "Epoch 4/10\n",
      "30/30 [==============================] - 15s 507ms/step - loss: 0.9309 - accuracy: 0.7397 - val_loss: 0.6981 - val_accuracy: 0.8109\n",
      "Epoch 5/10\n",
      "30/30 [==============================] - 16s 520ms/step - loss: 0.9136 - accuracy: 0.7334 - val_loss: 0.7370 - val_accuracy: 0.7815\n",
      "Epoch 6/10\n",
      "30/30 [==============================] - 16s 547ms/step - loss: 0.8874 - accuracy: 0.7408 - val_loss: 0.6758 - val_accuracy: 0.8067\n",
      "Epoch 7/10\n",
      "30/30 [==============================] - 16s 548ms/step - loss: 0.8722 - accuracy: 0.7408 - val_loss: 0.6572 - val_accuracy: 0.8235\n",
      "Epoch 8/10\n",
      "30/30 [==============================] - 16s 550ms/step - loss: 0.8661 - accuracy: 0.7471 - val_loss: 0.6884 - val_accuracy: 0.8193\n",
      "Epoch 9/10\n",
      "30/30 [==============================] - 16s 542ms/step - loss: 0.8486 - accuracy: 0.7387 - val_loss: 0.6362 - val_accuracy: 0.8235\n",
      "Epoch 10/10\n",
      "30/30 [==============================] - 17s 555ms/step - loss: 0.8418 - accuracy: 0.7418 - val_loss: 0.6552 - val_accuracy: 0.8235\n",
      "38/38 [==============================] - 7s 144ms/step\n",
      "['walk' 'walk' 'walk' ... 'walk' 'walk' 'walk']\n"
     ]
    }
   ],
   "source": [
    "# Example data (replace this with your own data)\n",
    "# Data preprocessing\n",
    "labels = [example[\"label\"] for example in df]\n",
    "sequences = [example[\"norm\"] for example in df]\n",
    "\n",
    "# Padding sequences\n",
    "max_sequence_length = max(len(seq) for seq in sequences)\n",
    "padded_sequences = pad_sequences(sequences, dtype='float32', padding='post', truncating='post')\n",
    "\n",
    "# Convert labels to numbers\n",
    "label_encoder = LabelEncoder()\n",
    "encoded_labels = label_encoder.fit_transform(labels)\n",
    "\n",
    "# One-hot encoding of labels\n",
    "one_hot_labels = to_categorical(encoded_labels)\n",
    "\n",
    "# Definition of the combined LSTM model\n",
    "input_sequence = Input(shape=(max_sequence_length, 1), name='input_sequence')\n",
    "masked_sequence = Masking(mask_value=0.0)(input_sequence)\n",
    "lstm_output = LSTM(100)(masked_sequence)\n",
    "output = Dense(len(np.unique(labels)), activation='softmax')(lstm_output)\n",
    "model_lstm_combined = Model(inputs=input_sequence, outputs=output)\n",
    "\n",
    "# Compilation of the combined LSTM model\n",
    "model_lstm_combined.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Training the model\n",
    "model_lstm_combined.fit(padded_sequences, one_hot_labels, epochs=10, batch_size=32, validation_split=0.2)\n",
    "\n",
    "# Inference with the combined model\n",
    "predictions = model_lstm_combined.predict(padded_sequences)\n",
    "\n",
    "# Convert predictions to labels\n",
    "predicted_labels_numeric = np.argmax(predictions, axis=1)\n",
    "predicted_labels_original = label_encoder.inverse_transform(predicted_labels_numeric)\n",
    "\n",
    "# Display predicted labels\n",
    "print(predicted_labels_original)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4246975",
   "metadata": {},
   "source": [
    "# Conclusion\n",
    "\n",
    "To conclude this use case, initially, I created a notebook on data exploration. This allowed me to better understand our data, the context surrounding it, and formulate my initial hypotheses on the potential model to use.\n",
    "\n",
    "Next, I researched the best model to implement for our problem, and I ultimately chose the LSTM model from RNNs, primarily for its ability to handle data with temporal sequences, a model I explained earlier in this notebook.\n",
    "\n",
    "Finally, I attempted to implement this model to recreate a football match. Unfortunately, the output of my model is not as expected."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
